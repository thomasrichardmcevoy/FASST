# Mental Models of Risk

## Capability and Deficits

A mental model is a cognitive map used by individuals in decision-making.  In cybersecurity, we assume that risks should represent a rational view of loss exposure from the point of view of the organization and that risk management approaches ought to represent a cost-effective response to diminishing this loss exposure.  But decision-makers and actors may not have mental models of cybersecurity risk which meet these goals. Indeed, the present of cognitive biases makes this almost certain. Gaps can also arise where an appreciation of possible cybersecurity strategies and tactics is absent. However, taking steps to diminish the effects of cognitive biases and to expand knowledge of cybersecurity strategies and possibilities can shrink these effects, moving the organization as a whole towards an improved mental model of risk.  This can affect all levels of the organization from senior managers to the shop floor. It also influences legislators and regulators.  Improved risk models should lead to more cost-effective risk strategies, optimizing security spend in the long term.  Almost certainly, a key factor in this is to move to quantitative risk management.

A poor mental model of risk may result in -

1. Increased effects of cognitive biases distorting decision-making [1]
2. Employing a limited number of cybersecurity strategies or tactics [2]
3. Under- or over- estimating risk [3] [4]
4. Inconsistent understanding of risk in different parts and layers of the organization which are also partly derived from other environmental factors [5]

Legislators and regulators can "gold plate" risk management guidance as can risk advisors and consultants - or they may misunderstand the seriousness of a risk and underplay its importance.  Senior management may as a result end up overspending on risk or refuse to spend on risk because the costs appear (intuitively) excessive or the risk minimal. Tick-box compliance can result in the case of the latter. 

Junior managers and staff may not understand the risks they are dealing with and take actions which appear safe to them (due to no previous experience of negative outcomes) but are, in fact, increasing their exposure to potential loss.  As a result, policy and procedures can be slackened - particularly, if this also eases the work burden.  

If burdensome risk measures are implemented and strictly enforced, work burdens can increases affecting productivity and costs.  Another possible effect is that progress on developing systems is halted by a view of associated risks being excessive or decision-making processes are paralyzed.

## Mapping to Generic Accimap

|Category | Number |
| --- | --- |
|EES  |4, 8, 10 |
|PPAA  |13, 14, 15, 19, 22, 25,26, 28|
|TOM   |30, 31, 32, 35, 40, 41, 43|
|LAGCM |44, 45, 46, 47, 48, 53, 54, 56|
|RBA   |58, 59, 60, 61, 62, 64, 66, 68|
|GPB   |72, 73, 74, 78 |

## Recommended Countermeasures

Organizations should adopt quantitative risk analysis and management e.g. FAIR [6] and overall take a consistent approach to risk estimation and risk management. Training in dealing with various scenarios can underpin this approach. Management awareness of cybersecurity strategies should be expanded through training to include both technical and non-technical (human and organizational) elements and cover all risk mitigation strategies (treat, avoid, transfer, accept) as well as tactics covering a wide range of possible countermeasures (e.g. NIST CSF - Identify, Protect, Detect, Respond, Recover)[7]. Training using gamification of cybersecurity thinking may be useful[1]. Risk management tactics should employ a range of measures rather than focusing on a single area and awareness of how countermeasures relate each other should form part of this analysis [6]. 

## References

- [1] Jalali, M. S., Siegel, M., & Madnick, S. (2019). Decision-making and biases in cybersecurity capability development: Evidence from a simulation game experiment. The Journal of Strategic Information Systems, 28(1), 66-82.
- [2] Kowalski, S., & Edwards, N. (2004). A security and trust framework for a Wireless World: A Cross Issue Approach. In Wireless World Research Forum no (Vol. 12).
- [3] Lewis, J. A. (2013). Raising the bar for cybersecurity. Center for Strategic and International Studies.
- [4] De Smidt, G., & Botzen, W. (2018). Perceptions of corporate cyber risks and insurance decision-making. The Geneva Papers on Risk and Insurance-Issues and Practice, 43(2), 239-274.
- [5] Kovačević, A., Putnik, N., & Tošković, O. (2020). Factors Related to Cyber Security Behavior. IEEE Access, 8, 125140-125148.
- [6] Freund, J., & Jones, J. (2014). Measuring and managing information risk: a FAIR approach. Butterworth-Heinemann.
- [7] [NIST CSF](https://www.nist.gov/cyberframework)
